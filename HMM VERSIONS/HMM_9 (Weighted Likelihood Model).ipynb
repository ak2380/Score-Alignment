{"cells":[{"cell_type":"markdown","metadata":{"id":"RsOcsgb5hVJ4"},"source":["**HMM Logic Sequence**\n","\n","- Input: MIDI file; audio file\n","- Separate audio into tonal & transient responses\n","- Move through the score sequentially\n","- At each point in the score, take the block of samples\n","- Transition matrix: geometric distribution model of state durations\n","- Emission probability: tonal likelihood using GP LML\n","- Viterbi algorithm 'windowed' to compute most probable state sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06YJpsHa0qsj"},"outputs":[],"source":["pip install pretty_midi pydub"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mO0Loa-9ixHq","executionInfo":{"status":"ok","timestamp":1741813266984,"user_tz":0,"elapsed":96568,"user":{"displayName":"Aditya Krishna","userId":"13297794755927845890"}},"outputId":"92646d53-654b-46a2-ece2-bf4c69773b82"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","from pretty_midi import PrettyMIDI\n","import matplotlib.pyplot as plt\n","import pretty_midi\n","\n","\n","def load_and_filter_midi_pretty(file_path, note_range=(60, 76), remove_note=None):\n","    \"\"\"\n","    Loads a MIDI file using pretty_midi, filters it to only include notes within the specified range,\n","    and optionally removes a specific note based on pitch and timing.\n","\n","    Args:\n","        file_path (str): Path to the MIDI file.\n","        note_range (tuple): A tuple specifying the (min_note, max_note) range.\n","        remove_note (tuple, optional): A tuple specifying the (pitch, start_time, time_tolerance)\n","                                       of the note to be removed.\n","\n","    Returns:\n","        PrettyMIDI: A new PrettyMIDI object with the filtered notes.\n","    \"\"\"\n","    try:\n","        midi_data = pretty_midi.PrettyMIDI(file_path)\n","\n","        for instrument in midi_data.instruments:\n","            filtered_notes = [\n","                note for note in instrument.notes\n","                if note_range[0] <= note.pitch <= note_range[1]\n","            ]\n","\n","            if remove_note:\n","                pitch_to_remove, start_time, time_tolerance = remove_note\n","                filtered_notes = [\n","                    note for note in filtered_notes\n","                    if not (note.pitch == pitch_to_remove and\n","                            abs(note.start - start_time) <= time_tolerance)\n","                ]\n","\n","            instrument.notes = filtered_notes  # Update notes\n","\n","        return midi_data\n","\n","    except Exception as e:\n","        print(f\"Error loading MIDI file: {e}\")\n","        return None\n","\n","\n","\n","def display_midi_and_notes_pretty(midi_data):\n","    \"\"\"\n","    Displays the notes of a PrettyMIDI object.\n","\n","    Args:\n","        midi_data (PrettyMIDI): The PrettyMIDI object to analyze.\n","\n","    Returns:\n","        list: A list of notes as tuples (start, end, pitch).\n","    \"\"\"\n","    try:\n","        notes = []\n","        for instrument in midi_data.instruments:\n","            for note in instrument.notes:\n","                notes.append((note.start, note.end, note.pitch))\n","\n","        # Sort notes by start time\n","        notes = sorted(notes, key=lambda x: x[0])\n","\n","        def midi_to_note_name(midi_number):\n","            \"\"\"Converts a MIDI note number to a piano note name.\"\"\"\n","            note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n","            octave = (midi_number // 12) - 1\n","            note = note_names[midi_number % 12]\n","            return f\"{note}{octave}\"\n","\n","        # Print and display note names\n","        note_names = [(start, end, midi_to_note_name(pitch)) for start, end, pitch in notes]\n","        print(\"\\nParsed Notes (start, end, pitch):\")\n","        for note in note_names:\n","            print(note)\n","\n","        return notes\n","\n","    except Exception as e:\n","        print(f\"Error displaying MIDI notes: {e}\")\n","        return []\n","\n","\n","def plot_midi_piano_roll_pretty(midi_data):\n","    \"\"\"\n","    Plots a piano roll visualization of a PrettyMIDI object.\n","\n","    Args:\n","        midi_data (PrettyMIDI): The PrettyMIDI object to visualize.\n","    \"\"\"\n","    try:\n","        notes = []\n","        times = []\n","\n","        for instrument in midi_data.instruments:\n","            for note in instrument.notes:\n","                notes.append(note.pitch)\n","                times.append(note.start)\n","\n","        # Plot the piano roll\n","        plt.figure(figsize=(10, 6))\n","        plt.scatter(times, notes, marker='o', color='blue', alpha=0.7)\n","        plt.xlabel(\"Time (seconds)\")\n","        plt.ylabel(\"MIDI Note Number\")\n","        plt.title(\"MIDI Piano Roll Visualization (PrettyMIDI)\")\n","        plt.yticks(range(min(notes), max(notes) + 1, 2))  # Display every 2 notes\n","        plt.grid(True, linestyle='--', alpha=0.6)\n","        plt.show()\n","\n","    except Exception as e:\n","        print(f\"Error plotting piano roll: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MgKNJpmZVC7e"},"outputs":[],"source":["note_to_remove = (71, 8.7, 0.1)  # Example: Remove note 70 around 8s with 0.2s tolerance\n","midi = load_and_filter_midi_pretty('/content/drive/MyDrive/furelise.mid', remove_note=note_to_remove)\n","plot_midi_piano_roll_pretty(midi)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"quuIY94cjr6k"},"outputs":[],"source":["import numpy as np\n","from scipy.stats import geom\n","import librosa\n","import pretty_midi\n","from scipy.ndimage import median_filter\n","from pydub import AudioSegment\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from IPython.display import Audio\n","from scipy.io import wavfile\n","from scipy.fft import fft, ifft\n","from scipy.signal.windows import hann\n","from scipy.linalg import cho_factor, cho_solve\n","\n","# Global parameters\n","time_window_size = 2048\n","hop_size = int(time_window_size * 0.5)\n","hmm_hop_size = 2048\n","window_size = 19\n","alpha = 0.4\n","eta = 0.1\n","sigma_p2 = 1e1  # Transient noise\n","\n","sigma_f2 = 2e-5  # Decay parameter for covariance\n","sigma_n2 = 3     # Noise variance\n","wq = [1.0]       # Weights for fundamentals\n","M = 9           # Number of harmonics\n","\n","sample_rate = 44100\n","T = 0.5\n","v = 2.37\n","\n","def parse_midi(midi_data):    #✅\n","    notes = []\n","    for instrument in midi_data.instruments:\n","        if not instrument.is_drum:\n","            for note in instrument.notes:\n","                notes.append((note.start, note.end, note.pitch))\n","    notes = sorted(notes, key=lambda x: x[0])\n","    print(notes)\n","    return notes\n","\n","def compute_transition_matrices(E_Z_list, block_size=2048):\n","    n_states = len(E_Z_list)\n","    avg_duration_samples = np.mean(E_Z_list)\n","    d_avg = avg_duration_samples / block_size\n","    p = 1 - 1/d_avg if d_avg > 1 else 0.0\n","    T = np.zeros((n_states, n_states))\n","    for i in range(n_states):\n","        T[i, i] = p\n","        if i < n_states - 1:\n","            T[i, i+1] = 1 - p\n","    T[n_states-1, n_states-1] = 1\n","    return T\n","\n","def extract_features():   #✅\n","    audio = AudioSegment.from_file('/content/drive/MyDrive/furelise.mp3')\n","    sample_rate = audio.frame_rate\n","    samples = np.array(audio.get_array_of_samples())\n","    if audio.channels > 1:\n","        samples = samples.reshape((-1, audio.channels))\n","        audio_data = samples.mean(axis=1)\n","    else:\n","        audio_data = samples\n","    time_hamming_window = hann(time_window_size)\n","    processed_audio = np.zeros(len(audio_data))\n","    for start in range(0, len(audio_data) - time_window_size, hop_size):\n","        segment = audio_data[start:start + time_window_size].astype(np.float64)\n","        segment *= time_hamming_window\n","        segment_ft = fft(segment)\n","        magnitude = np.abs(segment_ft)\n","        phase = np.angle(segment_ft)\n","        median_magnitude = alpha * median_filter(magnitude, size=(window_size,))\n","        filtered_magnitude = np.minimum(median_magnitude, magnitude)\n","        filtered_segment_ft = filtered_magnitude * np.exp(1j * phase)\n","        filtered_segment = ifft(filtered_segment_ft).real\n","        processed_audio[start:start + time_window_size] += filtered_segment * time_hamming_window\n","    processed_audio = np.int16(processed_audio / np.max(np.abs(processed_audio)) * 32767)\n","    tonal_audio = audio_data - processed_audio\n","    tonal_audio = np.int16(tonal_audio / np.max(np.abs(tonal_audio)) * 32767)\n","    return tonal_audio, processed_audio\n","\n","def harmonic_weight(m, T, v):   #✅\n","    return 1 / (1 + T * m**v)\n","\n","def covariance_function(tau, wq, midi_frequencies, T, v):\n","    cov = np.exp(-2 * np.pi**2 * sigma_f2 * tau**2)\n","    for fq in midi_frequencies:\n","        harmonic_sum = 0\n","        for m in range(1, M + 1):\n","            E_m = harmonic_weight(m, T, v)\n","            harmonic_sum += E_m * np.cos(2 * np.pi * m * fq * tau)\n","        cov += wq[0] * harmonic_sum\n","    return cov\n","\n","def compute_covariance_matrix(midi_frequencies, block_size, sample_rate, T, v):\n","    t = np.linspace(0, block_size / sample_rate, block_size)\n","    tau = t[:, None] - t[None, :]\n","    cov = np.exp(-2 * np.pi**2 * sigma_f2 * tau**2)\n","    harmonic_weights = np.array([harmonic_weight(m, T, v) for m in range(1, M + 1)])\n","    harmonic_weights = harmonic_weights[:, None, None]\n","    for fq in midi_frequencies:\n","        harmonic_matrix = harmonic_weights * np.cos(2 * np.pi * np.arange(1, M + 1)[:, None, None] * fq * tau)\n","        cov += np.sum(harmonic_matrix, axis=0)\n","    return cov\n","\n","def tonal_LML(y, K, sigma_n2):\n","    N = len(y)\n","    K_noise = K + sigma_n2 * np.eye(N)\n","    cho_decomp = cho_factor(K_noise, lower=True)\n","    alpha_sol = cho_solve(cho_decomp, y)\n","    log_det = 2 * np.sum(np.log(np.diag(cho_decomp[0])))\n","    LML = (\n","        -0.5 * np.dot(y.T, alpha_sol)\n","        - 0.5 * log_det\n","        - 0.5 * N * np.log(2 * np.pi)\n","    )\n","    return LML\n","\n","def compute_transient_likelihood(transient_block, sigma):\n","    N_samples = len(transient_block)\n","    return -0.5 * N_samples * np.log(2 * np.pi * sigma) - 0.5 * np.sum(transient_block.astype(np.float64)**2) / sigma\n","\n","def is_onset_state(state_index, midi_notes, current_time, onset_window=hmm_hop_size/sample_rate):\n","    onset_time = midi_notes[state_index][0]\n","    if current_time < onset_time:\n","        return False\n","    return (current_time - onset_time) < onset_window\n","\n","def compute_onset_strength(transient_block):\n","    transient_block = transient_block.astype(np.float64)\n","    rms = np.sqrt(np.mean(transient_block**2))\n","    return rms\n","\n","def train_gating_parameters(transient_audio, sample_rate, block_size=2048, hmm_hop_size=hmm_hop_size):\n","    \"\"\"\n","    Train gating parameters (k and theta) using librosa to detect onsets in the transient signal.\n","    Divide transient_audio into blocks and label a block as onset if any onset is detected within it.\n","    Then, compute the mean onset strength for onset and non-onset blocks and derive k and theta.\n","    \"\"\"\n","\n","    transient_float = transient_audio.astype(np.float32) / np.max(np.abs(transient_audio))\n","    onset_frames = librosa.onset.onset_detect(y=transient_float, sr=sample_rate)\n","    onset_times = librosa.frames_to_time(onset_frames, sr=sample_rate)\n","\n","    num_blocks = (len(transient_audio) - block_size) // hmm_hop_size + 1\n","    onset_strengths = []\n","    labels = []  # 1 for onset block, 0 for non-onset\n","    for i in range(num_blocks):\n","        start = i * hmm_hop_size\n","        block = transient_audio[start:start + block_size]\n","        s = compute_onset_strength(block)\n","        onset_strengths.append(s)\n","        block_start = start / sample_rate\n","        block_end = (start + block_size) / sample_rate\n","\n","        if np.any((onset_times >= block_start) & (onset_times < block_end)):\n","            labels.append(1)\n","        else:\n","            labels.append(0)\n","    onset_strengths = np.array(onset_strengths)\n","    labels = np.array(labels)\n","\n","    if np.sum(labels)==0 or np.sum(labels)==len(labels):\n","        k = 1.0\n","        theta = np.median(onset_strengths)\n","    else:\n","        mean_onset = np.mean(onset_strengths[labels==1])\n","        mean_non_onset = np.mean(onset_strengths[labels==0])\n","        theta = (mean_onset + mean_non_onset) / 2.0\n","        diff = mean_onset - mean_non_onset\n","        k = 1.0 / (diff + 1e-6)\n","    print(f\"Trained gating parameters: k = {k:.4f}, theta = {theta:.4f}\")\n","    return k, theta\n","\n","def compute_emission_probabilities(tonal_audio, transient_audio, sample_rate, midi_notes,\n","                                   block_size=2048, hmm_hop_size=hmm_hop_size,\n","                                   T_val=T, v_val=v, sigma_n2_val=sigma_n2,\n","                                   sigma_t2=sigma_p2, k_gate=1.0, theta=0.0, eta=0.1):\n","    \"\"\"\n","    Computes state-dependent emission probabilities.\n","    For each observation, compute the likelihood as a sum of the tonal likelihood\n","    and a gated transient likelihood:\n","\n","        L_trans = g * L_onset + (1 - g) * L_non-onset\n","\n","    where g is computed via a logistic function based on the onset strength.\n","    \"\"\"\n","    n_states = len(midi_notes)\n","    midi_starts = [note[0] for note in midi_notes]\n","    base_frequencies = []\n","    for note in midi_notes:\n","        _, _, pitch = note\n","        base_frequency = 440.0 * 2 ** ((pitch - 69) / 12.0)\n","        base_frequencies.append(base_frequency)\n","    n_obs = (len(tonal_audio) - block_size) // hmm_hop_size + 1\n","    emissions = []\n","    allowed_max_states = []  # one allowed index per observation\n","\n","    for obs_idx, start in enumerate(range(0, len(tonal_audio) - block_size, hmm_hop_size)):\n","        tonal_block = tonal_audio[start:start + block_size]\n","        transient_block = transient_audio[start:start + block_size]\n","        emission_vector = np.full(n_states, -np.inf)\n","        current_time = start / sample_rate\n","        allowed_idx = np.searchsorted(midi_starts, current_time, side='right') - 1\n","        allowed_idx = max(allowed_idx, 0)\n","        allowed_max_states.append(allowed_idx)\n","        lower_bound = max(0, allowed_idx - 3)\n","        upper_bound = min(n_states, allowed_idx + 2 + 1)\n","\n","        onset_strength = compute_onset_strength(transient_block)\n","        print(f\"Block starting at {start} (time {current_time:.2f})\")\n","\n","        for i in range(lower_bound, upper_bound):\n","            candidate_frequency = base_frequencies[i]\n","            K = compute_covariance_matrix([candidate_frequency], block_size, sample_rate, T_val, v_val)\n","            log_likelihood_tonal = tonal_LML(tonal_block, K, sigma_n2_val)\n","\n","            if i == allowed_idx and is_onset_state(i, midi_notes, current_time):\n","                onset_strength = compute_onset_strength(transient_block)\n","                g = 1.0 / (1.0 + np.exp(-k_gate * (onset_strength - theta)))\n","                print(f\"TRANSIENT DETETCTED FOR STATE {i}\")\n","                print(\"Onset Strength: \", onset_strength, \" Gating Variable: \", g)\n","            else:\n","                g = 0.0\n","\n","            L_onset = compute_transient_likelihood(transient_block, sigma_t2)\n","            L_non_onset = compute_transient_likelihood(transient_block, sigma_t2 * eta)\n","\n","            log_likelihood_trans = g * L_onset + (1 - g) * L_non_onset\n","            combined_log_likelihood = log_likelihood_tonal + log_likelihood_trans\n","            emission_vector[i] = combined_log_likelihood\n","\n","        print(f\"Allowed max state: {allowed_idx}\")\n","        print(emission_vector)\n","        emissions.append(emission_vector)\n","    return np.array(emissions), np.array(allowed_max_states)\n","\n","def viterbi(transition_matrix, emissions, allowed_max_states):\n","    n_obs, n_states = emissions.shape\n","    dp = np.full((n_obs, n_states), -np.inf)\n","    backpointer = np.zeros((n_obs, n_states), dtype=int)\n","    for j in range(n_states):\n","        if j <= allowed_max_states[0]:\n","            dp[0, j] = emissions[0, j]\n","    for t in range(1, n_obs):\n","        for j in range(n_states):\n","            if j > allowed_max_states[t]:\n","                dp[t, j] = -np.inf\n","                continue\n","            max_prob = -np.inf\n","            best_state = 0\n","            for i in range(n_states):\n","                if dp[t - 1, i] == -np.inf:\n","                    continue\n","                if transition_matrix[i, j] > 0:\n","                    prob = dp[t - 1, i] + np.log(transition_matrix[i, j])\n","                else:\n","                    prob = -np.inf\n","                if prob > max_prob:\n","                    max_prob = prob\n","                    best_state = i\n","            dp[t, j] = max_prob + emissions[t, j]\n","            backpointer[t, j] = best_state\n","    best_last_state = np.argmax(dp[-1])\n","    state_sequence = np.zeros(n_obs, dtype=int)\n","    state_sequence[-1] = best_last_state\n","    for t in range(n_obs - 1, 0, -1):\n","        state_sequence[t - 1] = backpointer[t, state_sequence[t]]\n","    return state_sequence.tolist()\n","\n","def log_sum_exp(log_values):\n","    max_log = np.max(log_values)\n","    return max_log + np.log(np.sum(np.exp(log_values - max_log)))\n","\n","def forward_algorithm(transition_matrix, emissions, allowed_max_states):\n","    n_obs, n_states = emissions.shape\n","    alpha = np.full((n_obs, n_states), -np.inf)\n","    for j in range(n_states):\n","        if j <= allowed_max_states[0]:\n","            alpha[0, j] = emissions[0, j]\n","    for t in range(1, n_obs):\n","        for j in range(n_states):\n","            if j > allowed_max_states[t]:\n","                continue\n","            prev_logs = []\n","            for i in range(n_states):\n","                if alpha[t-1, i] > -np.inf and transition_matrix[i, j] > 0:\n","                    prev_logs.append(alpha[t-1, i] + np.log(transition_matrix[i, j]))\n","            if prev_logs:\n","                alpha[t, j] = emissions[t, j] + log_sum_exp(np.array(prev_logs))\n","    return alpha\n","\n","def compute_total_log_likelihood(alpha):\n","    return log_sum_exp(alpha[-1, :])\n","\n","\n","\n","\n","\n","def main(midi_file):\n","    midi_notes = parse_midi(midi_file)\n","    tonal, transient = extract_features()\n","    sample_rate = 44100\n","    E_Z_list = [int((note[1] - note[0]) * sample_rate) for note in midi_notes]\n","    transition_matrix = compute_transition_matrices(E_Z_list, block_size=2048)\n","\n","    k_gate_trained, theta_trained = train_gating_parameters(transient, sample_rate, block_size=2048, hmm_hop_size=hmm_hop_size)\n","\n","    g_series = []\n","    g_times = []\n","    rms_vals = []\n","    block_size = 2048\n","    for start in range(0, len(transient) - block_size, block_size):\n","        transient_block = transient[start:start+block_size]\n","        current_time = start / sample_rate\n","        onset_strength = compute_onset_strength(transient_block)\n","\n","        midi_starts = [note[0] for note in midi_notes]\n","        allowed_idx = np.searchsorted(midi_starts, current_time, side='right') - 1\n","        allowed_idx = max(allowed_idx, 0)\n","\n","        g_val = 1.0 / (1.0 + np.exp(-k_gate_trained * (onset_strength - theta_trained)))\n","        rms_val = np.sqrt(np.mean(transient_block**2))\n","\n","        g_series.append(g_val)\n","        rms_vals.append(rms_val)\n","        g_times.append(current_time)\n","\n","\n","    fig, ax1 = plt.subplots(figsize=(12, 6))\n","\n","    t = np.linspace(0, len(transient)/sample_rate, len(transient))\n","    ax1.plot(t, transient, label=\"Transient Audio\", color=\"blue\")\n","    ax1.set_xlabel(\"Time (s)\")\n","    ax1.set_ylabel(\"Transient Amplitude\", color=\"blue\")\n","    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n","\n","    ax2 = ax1.twinx()\n","    ax2.plot(g_times, g_series, label=\"Gating Variable (g)\", color=\"red\", marker=\"o\", linestyle=\"-\")\n","    ax2.set_ylabel(\"Gating Value (g)\", color=\"red\")\n","    ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n","\n","\n","    plt.title(\"Transient Audio with Gating Variable Overlaid\")\n","    plt.show()\n","\n","\n","    emissions, allowed_max_states = compute_emission_probabilities(\n","        tonal, transient, sample_rate, midi_notes,\n","        block_size=2048, hmm_hop_size=hmm_hop_size,\n","        T_val=T, v_val=v, sigma_n2_val=sigma_n2, sigma_t2=sigma_p2,\n","        k_gate=k_gate_trained, theta=theta_trained, eta=eta\n","    )\n","\n","    alpha_mat = forward_algorithm(transition_matrix, emissions, allowed_max_states)\n","    total_log_likelihood = compute_total_log_likelihood(alpha_mat)\n","    print(\"Alpha matrix:\", alpha_mat)\n","    print(\"Total log-likelihood of the observation sequence:\", total_log_likelihood)\n","    state_sequence = viterbi(transition_matrix, emissions, allowed_max_states)\n","    print(\"Most probable state sequence:\", state_sequence)\n","    return alpha_mat, total_log_likelihood, state_sequence\n","\n","# Run the HMM with your MIDI file (assumed to be loaded as variable 'midi')\n","midi_notes = parse_midi(midi)\n","alpha_matrix, total_ll, viterbi_output = main(midi)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTp9OZvHuncG"},"outputs":[],"source":["def plot_viterbi_output(midi_data, state_sequence, figsize, sample_rate=44100, hop_size=hmm_hop_size):\n","    \"\"\"\n","    Plots a piano roll visualization of a PrettyMIDI object with small 'x' markers at every observation,\n","    where the y-value for each marker is chosen based on the Viterbi state. In particular, if the state\n","    is 0 then the marker is placed at the pitch of the first note (notes[0]); otherwise, it uses the note\n","    corresponding to the state value (if valid).\n","\n","    Args:\n","        midi_data (pretty_midi.PrettyMIDI): The PrettyMIDI object to visualize.\n","        state_sequence (list or np.array): Viterbi state indices at each observation.\n","        sample_rate (int): Audio sample rate (samples per second).\n","        hop_size (int): Number of samples between observations in state_sequence.\n","    \"\"\"\n","    import numpy as np\n","    import matplotlib.pyplot as plt\n","\n","    try:\n","        # Extract note pitches and start times from all instruments.\n","        notes = []\n","        times = []\n","        for instrument in midi_data.instruments:\n","            for note in instrument.notes:\n","                notes.append(note.pitch)\n","                times.append(note.start)\n","\n","        print(notes)\n","\n","        if not notes:\n","            print(\"No notes found in the MIDI data.\")\n","            return\n","\n","        plt.figure(figsize=figsize)\n","        plt.scatter(times, notes, marker='o', color='blue', alpha=0.7)\n","        plt.xlabel(\"Time (seconds)\")\n","        plt.ylabel(\"MIDI Note Number\")\n","        plt.title(\"MIDI Piano Roll Visualization & Viterbi Decoded States\")\n","        plt.yticks(range(min(notes), max(notes) + 1, 2))\n","        plt.grid(True, linestyle='--', alpha=0.6)\n","\n","        obs_times = np.arange(len(state_sequence)) * (hop_size / sample_rate)\n","\n","\n","        colors = ['red', 'green', 'blue']\n","\n","        for i, state in enumerate(state_sequence):\n","            if state == 0:\n","                note_val = notes[0]\n","            else:\n","                if state < len(notes):\n","                    note_val = notes[state]\n","                else:\n","                    continue\n","            color = colors[state % len(colors)]\n","            plt.text(obs_times[i], note_val, 'x', color=color,\n","                     fontsize=8, horizontalalignment='center', verticalalignment='center')\n","\n","        segments = []\n","        seg_start = 0\n","        for i in range(1, len(state_sequence)):\n","            if state_sequence[i] != state_sequence[i - 1]:\n","                segments.append((seg_start, i - 1, state_sequence[i - 1]))\n","                seg_start = i\n","        segments.append((seg_start, len(state_sequence) - 1, state_sequence[-1]))\n","\n","        ax = plt.gca()\n","        top_y = max(notes) + 2\n","        for seg in segments:\n","            seg_start_idx, seg_end_idx, state = seg\n","            block_start_time = obs_times[seg_start_idx]\n","            block_end_time = obs_times[seg_end_idx] + (hop_size / sample_rate)\n","            mid_time = (block_start_time + block_end_time) / 2.0\n","            ax.text(mid_time, top_y, f\"S={state}\",\n","                    horizontalalignment='center',\n","                    verticalalignment='bottom',\n","                    fontsize=10,\n","                    bbox=dict(facecolor='white', alpha=0.6, edgecolor='none'))\n","\n","        plt.show()\n","\n","    except Exception as e:\n","        print(f\"Error plotting piano roll: {e}\")\n","\n","\n","    midi_notes = []\n","    for instr in midi_data.instruments:\n","        if not instr.is_drum:\n","            for note in instr.notes:\n","                midi_notes.append((note.start, note.end, note.pitch))\n","    midi_notes.sort(key=lambda x: x[0])\n","    starts = [n[0] for n in midi_notes]\n","\n","    true_states = []\n","    for t in obs_times:\n","        idx = np.searchsorted(starts, t, side='right') - 1\n","        true_states.append(max(idx, 0))\n","    true_states = np.array(true_states)\n","\n","    seq = np.array(state_sequence)\n","    correct = np.sum(seq == true_states)\n","    total   = len(seq)\n","    acc     = correct / total * 100\n","\n","    print(f\"Alignment: {correct}/{total} frames correct ({acc:.1f}%)\")"]},{"cell_type":"code","source":["plot_viterbi_output(midi, viterbi_output, (22,10), sample_rate, hmm_hop_size)"],"metadata":{"id":"GZgfC4-w3gEC"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1PLBJvnhLEw14TdqllkDXwP9ZA0pKJK_Y","timestamp":1741201356775},{"file_id":"1N5vNkCJxumU1qGiFN-s5MZAY-z7xxsgF","timestamp":1740496004550},{"file_id":"1-OAqBugFhfK5h3asOs98tyiMYbklvOPM","timestamp":1740416215165},{"file_id":"1OWxZiqaUBQrIv-Y9QUmsmgc56JiQq462","timestamp":1739898152138},{"file_id":"1uisqEXuNgk1mrMBC5TpaRjn0z2mFts8B","timestamp":1739893939645},{"file_id":"1Dv4L-G9EQ73_5nTogqp0u-Uop4sktRg-","timestamp":1739550268450},{"file_id":"1hUNjGdjlmKv9ZdM81F3RXHXaO0Acnv0e","timestamp":1739309648415}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}