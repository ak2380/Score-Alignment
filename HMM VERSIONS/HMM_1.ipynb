{"cells":[{"cell_type":"markdown","source":["**HMM Logic Sequence**\n","\n","- Input: MIDI file; audio file\n","- Separate audio into tonal & transient responses\n","- Move through the score sequentially\n","- At each point in the score, take the block of samples\n","- Transition matrix: geometric distribution model of state durations\n","- Emission probability: tonal likelihood using GP LML\n","- Viterbi algorithm 'windowed' to compute most probable state sequence"],"metadata":{"id":"RsOcsgb5hVJ4"}},{"cell_type":"code","source":["pip install pretty_midi pydub"],"metadata":{"id":"06YJpsHa0qsj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","from pretty_midi import PrettyMIDI\n","import matplotlib.pyplot as plt\n","\n","\n","def load_and_filter_midi_pretty(file_path, note_range=(59, 73)):\n","    \"\"\"\n","    Loads a MIDI file using pretty_midi and filters it to only include notes within the specified range.\n","\n","    Args:\n","        file_path (str): Path to the MIDI file.\n","        note_range (tuple): A tuple specifying the (min_note, max_note) range.\n","\n","    Returns:\n","        PrettyMIDI: A new PrettyMIDI object with the filtered notes.\n","    \"\"\"\n","    try:\n","        # Load the MIDI file\n","        midi_data = PrettyMIDI(file_path)\n","\n","        # Filter notes for each instrument\n","        for instrument in midi_data.instruments:\n","            filtered_notes = [\n","                note for note in instrument.notes\n","                if note.pitch >= note_range[0] and note.pitch <= note_range[1]\n","            ]\n","            instrument.notes = filtered_notes\n","\n","        return midi_data\n","\n","    except Exception as e:\n","        print(f\"Error loading MIDI file: {e}\")\n","        return None\n","\n","\n","def display_midi_and_notes_pretty(midi_data):\n","    \"\"\"\n","    Displays the notes of a PrettyMIDI object.\n","\n","    Args:\n","        midi_data (PrettyMIDI): The PrettyMIDI object to analyze.\n","\n","    Returns:\n","        list: A list of notes as tuples (start, end, pitch).\n","    \"\"\"\n","    try:\n","        notes = []\n","        for instrument in midi_data.instruments:\n","            for note in instrument.notes:\n","                notes.append((note.start, note.end, note.pitch))\n","\n","        # Sort notes by start time\n","        notes = sorted(notes, key=lambda x: x[0])\n","\n","        def midi_to_note_name(midi_number):\n","            \"\"\"Converts a MIDI note number to a piano note name.\"\"\"\n","            note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n","            octave = (midi_number // 12) - 1\n","            note = note_names[midi_number % 12]\n","            return f\"{note}{octave}\"\n","\n","        # Print and display note names\n","        note_names = [(start, end, midi_to_note_name(pitch)) for start, end, pitch in notes]\n","        print(\"\\nParsed Notes (start, end, pitch):\")\n","        for note in note_names:\n","            print(note)\n","\n","        return notes\n","\n","    except Exception as e:\n","        print(f\"Error displaying MIDI notes: {e}\")\n","        return []\n","\n","\n","def plot_midi_piano_roll_pretty(midi_data):\n","    \"\"\"\n","    Plots a piano roll visualization of a PrettyMIDI object.\n","\n","    Args:\n","        midi_data (PrettyMIDI): The PrettyMIDI object to visualize.\n","    \"\"\"\n","    try:\n","        notes = []\n","        times = []\n","\n","        for instrument in midi_data.instruments:\n","            for note in instrument.notes:\n","                notes.append(note.pitch)\n","                times.append(note.start)\n","\n","        # Plot the piano roll\n","        plt.figure(figsize=(10, 6))\n","        plt.scatter(times, notes, marker='o', color='blue', alpha=0.7)\n","        plt.xlabel(\"Time (seconds)\")\n","        plt.ylabel(\"MIDI Note Number\")\n","        plt.title(\"MIDI Piano Roll Visualization (PrettyMIDI)\")\n","        plt.yticks(range(min(notes), max(notes) + 1, 2))  # Display every 2 notes\n","        plt.grid(True, linestyle='--', alpha=0.6)\n","        plt.show()\n","\n","    except Exception as e:\n","        print(f\"Error plotting piano roll: {e}\")\n","\n","\n","# Example usage\n","midi = load_and_filter_midi_pretty('/content/drive/MyDrive/cmajorscale.mid')\n","# display_midi_and_notes_pretty(midi)\n","plot_midi_piano_roll_pretty(midi)\n"],"metadata":{"id":"mO0Loa-9ixHq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from scipy.stats import geom\n","import librosa\n","import pretty_midi\n","from scipy.ndimage import median_filter\n","from pydub import AudioSegment\n","import librosa\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from IPython.display import Audio\n","from scipy.io import wavfile\n","from scipy.fft import fft, ifft\n","from scipy.signal.windows import hamming, hann\n","from scipy.linalg import cho_factor, cho_solve\n","\n","\n","\n","\n","audio = AudioSegment.from_file('/content/drive/MyDrive/cmajorscale.mp3')\n","sample_rate = audio.frame_rate\n","audio_data = np.array(audio.get_array_of_samples())\n","\n","time_window_size = 2048\n","hop_size = int(time_window_size * 0.5)\n","hmm_hop_size = 5000\n","window_size = 19\n","alpha = 0.4\n","sigma_p2 = 1e1 # Transient noise\n","\n","sigma_f2 = 2e-5  # Decay parameter for covariance\n","sigma_n2 = 3  # Noise variance\n","wq = [1.0]  # Weights for fundamentals\n","M = 9  # Number of harmonics\n","\n","sample_rate = 44100\n","\n","T = 0.5\n","v = 2.37\n","\n","\n","\n","\n","def parse_midi(midi_data):    #✅\n","    notes = []\n","    for instrument in midi_data.instruments:\n","        if not instrument.is_drum:\n","            for note in instrument.notes:\n","                notes.append((note.start, note.end, note.pitch))\n","    notes = sorted(notes, key=lambda x: x[0])\n","    print(notes)\n","    return notes\n","\n","\n","def compute_transition_matrices(E_Z_list, block_size=2048):\n","    \"\"\"\n","    Compute a single left-to-right transition matrix for the entire score.\n","    Each state corresponds to a score event (note/chord) from the MIDI file.\n","\n","    We first compute the average note duration (in samples) from E_Z_list\n","    and then convert it to the average number of blocks (of size 'block_size').\n","    For an average of d_avg blocks per note, a simple duration model is:\n","\n","        self-transition probability:   p = 1 - 1/d_avg\n","        transition to next state:       1 - p\n","\n","    The resulting matrix is of size (n_states x n_states) where n_states is\n","    the number of MIDI events.\n","    \"\"\"\n","    n_states = len(E_Z_list)\n","    avg_duration_samples = np.mean(E_Z_list)\n","    d_avg = avg_duration_samples / block_size\n","\n","    p = 1 - 1/d_avg if d_avg > 1 else 0.0\n","\n","    T = np.zeros((n_states, n_states))\n","    for i in range(n_states):\n","        T[i, i] = p\n","        if i < n_states - 1:\n","            T[i, i+1] = 1 - p\n","\n","    T[n_states-1, n_states-1] = 1\n","    return T\n","\n","\n","\n","def extract_features():   #✅\n","    audio = AudioSegment.from_file('/content/drive/MyDrive/cmajorscale.mp3')\n","    sample_rate = audio.frame_rate\n","    samples = np.array(audio.get_array_of_samples())\n","\n","    if audio.channels > 1:   # If the audio is stereo, reshape and convert to mono\n","        samples = samples.reshape((-1, audio.channels))\n","        audio_data = samples.mean(axis=1)\n","    else:\n","        audio_data = samples\n","\n","    time_hamming_window = hann(time_window_size)\n","    randomized_phase = np.random.uniform(-np.pi, np.pi, time_window_size)\n","    processed_audio = np.zeros(len(audio_data))\n","    transient_probabilities = []\n","\n","    time_hamming_window = hann(time_window_size)\n","    randomized_phase = np.random.uniform(-np.pi, np.pi, time_window_size)\n","\n","    processed_audio = np.zeros(len(audio_data))\n","\n","    for start in range(0, len(audio_data) - time_window_size, hop_size):\n","        segment = audio_data[start:start + time_window_size].astype(np.float64)\n","        segment *= time_hamming_window\n","\n","        segment_ft = fft(segment)\n","        magnitude = np.abs(segment_ft)\n","        phase = np.angle(segment_ft)\n","\n","        median_magnitude = alpha * median_filter(magnitude, size=(window_size,))\n","        filtered_magnitude = np.minimum(median_magnitude, magnitude)\n","\n","        filtered_segment_ft = filtered_magnitude * np.exp(1j * phase)\n","        filtered_segment = ifft(filtered_segment_ft).real\n","\n","        processed_audio[start:start + time_window_size] += filtered_segment * time_hamming_window\n","\n","    processed_audio = np.int16(processed_audio / np.max(np.abs(processed_audio)) * 32767)\n","\n","    tonal_audio = audio_data - processed_audio\n","    tonal_audio = np.int16(tonal_audio / np.max(np.abs(tonal_audio)) * 32767)\n","\n","    return tonal_audio, processed_audio\n","\n","\n","def harmonic_weight(m, T, v):   #✅\n","    return 1 / (1 + T * m**v)\n","\n","\n","def covariance_function(tau, wq, midi_frequencies, T, v):\n","    cov = np.exp(-2 * np.pi**2 * sigma_f2 * tau**2)\n","    for fq in midi_frequencies:\n","        harmonic_sum = 0\n","        for m in range(1, M + 1):\n","            E_m = harmonic_weight(m, T, v)\n","            harmonic_sum += E_m * np.cos(2 * np.pi * m * fq * tau)\n","        cov += wq[0] * harmonic_sum\n","    return cov\n","\n","\n","def compute_covariance_matrix(midi_frequencies, block_size, sample_rate, T, v):\n","    t = np.linspace(0, block_size / sample_rate, block_size)\n","    tau = t[:, None] - t[None, :]\n","\n","    cov = np.exp(-2 * np.pi**2 * sigma_f2 * tau**2)\n","\n","    harmonic_weights = np.array([harmonic_weight(m, T, v) for m in range(1, M + 1)])\n","    harmonic_weights = harmonic_weights[:, None, None]\n","\n","    for fq in midi_frequencies:\n","        harmonic_matrix = harmonic_weights * np.cos(2 * np.pi * np.arange(1, M + 1)[:, None, None] * fq * tau)\n","        cov += np.sum(harmonic_matrix, axis=0)\n","\n","    return cov\n","\n","\n","def tonal_LML(y, K, sigma_n2):\n","    N = len(y)\n","    K_noise = K + sigma_n2 * np.eye(N)\n","    cho_decomp = cho_factor(K_noise, lower=True)\n","    alpha = cho_solve(cho_decomp, y)\n","    log_det = 2 * np.sum(np.log(np.diag(cho_decomp[0])))\n","    LML = (\n","        -0.5 * np.dot(y.T, alpha)\n","        - 0.5 * log_det\n","        - 0.5 * N * np.log(2 * np.pi)\n","    )\n","    return LML\n","\n","\n","def compute_emission_probabilities(tonal_audio, sample_rate, midi_notes,\n","                                   block_size=2048, hmm_hop_size=5000,\n","                                   T_val=T, v_val=v, sigma_n2_val=sigma_n2):\n","    \"\"\"\n","    For each observation, this function computes an emission probability vector\n","    whose length equals the number of score events (notes/chords) in the MIDI file.\n","    The likelihood for each event is computed using its base frequency (derived\n","    from its MIDI pitch) via the covariance matrix and tonal log marginal likelihood.\n","    \"\"\"\n","    n_states = len(midi_notes)\n","\n","    base_frequencies = []\n","    for note in midi_notes:\n","        _, _, pitch = note\n","        base_frequency = 440.0 * 2**((pitch - 69) / 12.0)\n","        base_frequencies.append(base_frequency)\n","\n","    n_obs = (len(tonal_audio) - block_size) // hmm_hop_size + 1\n","    emissions = []\n","\n","    for obs_idx, start in enumerate(range(0, len(tonal_audio) - block_size, hmm_hop_size)):\n","        block = tonal_audio[start:start + block_size]\n","        emission_vector = np.zeros(n_states)\n","\n","        for i in range(n_states):\n","            candidate_frequency = base_frequencies[i]\n","            K = compute_covariance_matrix([candidate_frequency], block_size, sample_rate, T_val, v_val)\n","            log_likelihood = tonal_LML(block, K, sigma_n2_val)\n","            emission_vector[i] = log_likelihood\n","\n","        print(start)\n","        print(emission_vector)\n","\n","        emissions.append(emission_vector)\n","\n","    return np.array(emissions)\n","\n","\n","\n","\n","def viterbi(transition_matrix, emissions):\n","    \"\"\"\n","    Given a transition matrix (of shape [n_states, n_states]) and an emission\n","    probability matrix (of shape [n_obs, n_states]), this function computes the\n","    most likely sequence of states using the full Viterbi algorithm.\n","    \"\"\"\n","    n_obs, n_states = emissions.shape\n","\n","    dp = np.full((n_obs, n_states), -np.inf)\n","    backpointer = np.zeros((n_obs, n_states), dtype=int)\n","\n","    dp[0] = emissions[0]\n","\n","    for t in range(1, n_obs):\n","        for j in range(n_states):\n","            max_prob = -np.inf\n","            best_state = 0\n","            for i in range(n_states):\n","                if transition_matrix[i, j] > 0:\n","                    prob = dp[t - 1, i] + np.log(transition_matrix[i, j])\n","                else:\n","                    prob = -np.inf\n","                if prob > max_prob:\n","                    max_prob = prob\n","                    best_state = i\n","            dp[t, j] = max_prob + emissions[t, j]\n","            backpointer[t, j] = best_state\n","\n","    best_last_state = np.argmax(dp[-1])\n","    states = np.zeros(n_obs, dtype=int)\n","    states[-1] = best_last_state\n","    for t in range(n_obs - 1, 0, -1):\n","        states[t - 1] = backpointer[t, states[t]]\n","\n","    return states.tolist()\n","\n","\n","    #USE FULL Viterbi\n","    #HMM Forward Algo?\n","\n","\n","def main(midi_file):\n","    midi_notes = parse_midi(midi_file)\n","    tonal, transient = extract_features()\n","\n","    E_Z_list = [(note[1] - note[0]) * 44100 for note in midi_notes]\n","\n","    transition_matrix = compute_transition_matrices(E_Z_list, block_size=2048)\n","\n","    E = compute_emission_probabilities(tonal, sample_rate, midi_notes,\n","                                       block_size=2048, hmm_hop_size=5000,\n","                                       T_val=T, v_val=v, sigma_n2_val=sigma_n2)\n","\n","    # Run the full Viterbi algorithm over the entire observation sequence.\n","    state_sequence = viterbi(transition_matrix, E)\n","    print(\"Most probable state sequence:\", state_sequence)\n","\n","\n","\n","\n","# Run the HMM\n","midi_notes = parse_midi(midi)\n","main(midi)\n","\n","\n"],"metadata":{"id":"84dlwJ_EqAa3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def plot_midi_piano_roll_pretty_intervals(midi_data, sample_rate, vertical_line_pattern=None):\n","    \"\"\"\n","    Plots a piano roll visualization of a PrettyMIDI object with vertical lines\n","    colored according to a specified pattern.\n","\n","    Args:\n","        midi_data (PrettyMIDI): The PrettyMIDI object to visualize.\n","        sample_rate (int or float): The sample rate (samples per second).\n","                                    Vertical lines will be drawn every 5000 samples.\n","        vertical_line_pattern (list of tuples, optional): A list of tuples specifying\n","            (number_of_lines, color) for vertical lines.\n","            For example, [(4, 'red'), (2, 'blue'), (3, 'red')] means:\n","                - The first 4 lines are red,\n","                - The next 2 lines are blue,\n","                - The following 3 lines are red,\n","                and then the pattern repeats.\n","            Defaults to [(1, 'red')], which colors all vertical lines red.\n","    \"\"\"\n","    # Use a default pattern if none is provided\n","    if vertical_line_pattern is None:\n","        vertical_line_pattern = [(1, 'red')]\n","\n","    try:\n","        # Gather note pitches and start times from all instruments\n","        notes = []\n","        times = []\n","        for instrument in midi_data.instruments:\n","            for note in instrument.notes:\n","                notes.append(note.pitch)\n","                times.append(note.start)\n","\n","        # Create the piano roll scatter plot\n","        plt.figure(figsize=(18, 8))\n","        plt.scatter(times, notes, marker='o', color='blue', alpha=0.7)\n","        plt.xlabel(\"Time (seconds)\")\n","        plt.ylabel(\"MIDI Note Number\")\n","        plt.title(\"MIDI Piano Roll Visualization (PrettyMIDI)\")\n","        plt.yticks(range(min(notes), max(notes) + 1, 2))  # Display every 2 notes\n","        plt.grid(True, linestyle='--', alpha=0.6)\n","\n","        # Calculate the time interval corresponding to 5000 samples.\n","        interval = 5000 / sample_rate\n","\n","        # Determine the maximum time from the notes to cover the plot duration\n","        t_max = max(times) if times else 0\n","        # Compute all time positions for vertical lines\n","        positions = np.arange(0, t_max + interval, interval)\n","\n","        # Prepare to cycle through the provided vertical line color pattern.\n","        pattern_idx = 0\n","        group_count, current_color = vertical_line_pattern[pattern_idx]\n","        count_in_group = 0\n","\n","        # Draw each vertical line with the color from the pattern.\n","        for t in positions:\n","            plt.axvline(x=t, color=current_color, linestyle='--', alpha=0.5)\n","            count_in_group += 1\n","            if count_in_group >= group_count:\n","                # Move to the next group in the pattern (and cycle if needed)\n","                pattern_idx = (pattern_idx + 1) % len(vertical_line_pattern)\n","                group_count, current_color = vertical_line_pattern[pattern_idx]\n","                count_in_group = 0\n","\n","        plt.show()\n","\n","    except Exception as e:\n","        print(f\"Error plotting piano roll: {e}\")\n","\n","\n","pattern = [(6, 'red'), (4, 'blue'), (5, 'red'), (4, 'blue'), (5, 'red'), (4, 'blue'), (4, 'red'), (22, 'blue'), (5, 'red'), (4, 'blue'), (5, 'red'), (4, 'blue'), (4, 'red'), (4, 'blue')]\n","plot_midi_piano_roll_pretty_intervals(midi, sample_rate=44100, vertical_line_pattern=pattern)"],"metadata":{"id":"-oCU0aNgbkJT"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1hUNjGdjlmKv9ZdM81F3RXHXaO0Acnv0e","timestamp":1739309648415}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}